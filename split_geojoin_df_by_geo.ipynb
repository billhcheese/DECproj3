{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e61ec057-243c-4026-b52b-21d6f822b41e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import geopandas\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d375149e-a1c5-45ff-b51e-860cb14e46d7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved DataFrame for category 'NSA' as table 'learningpipeline.serve.ChangeSince2010_nsa'\nSaved DataFrame for category 'Tract' as table 'learningpipeline.serve.ChangeSince2010_tract'\nSaved DataFrame for category 'NPU' as table 'learningpipeline.serve.ChangeSince2010_npu'\nSaved DataFrame for category 'County' as table 'learningpipeline.serve.ChangeSince2010_county'\nSaved DataFrame for category 'State' as table 'learningpipeline.serve.ChangeSince2010_state'\nSaved DataFrame for category 'RC' as table 'learningpipeline.serve.ChangeSince2010_rc'\nSaved DataFrame for category 'ARWDB7' as table 'learningpipeline.serve.ChangeSince2010_arwdb7'\nSaved DataFrame for category 'Nation' as table 'learningpipeline.serve.ChangeSince2010_nation'\nSaved DataFrame for category 'SuperDistrict' as table 'learningpipeline.serve.ChangeSince2010_superdistrict'\nSaved DataFrame for category 'AtlCityCouncil' as table 'learningpipeline.serve.ChangeSince2010_atlcitycouncil'\nSaved DataFrame for category 'UWGA13' as table 'learningpipeline.serve.ChangeSince2010_uwga13'\nSaved DataFrame for category 'ARC21' as table 'learningpipeline.serve.ChangeSince2010_arc21'\nSaved DataFrame for category 'AAA' as table 'learningpipeline.serve.ChangeSince2010_aaa'\nSaved DataFrame for category 'MetroWater15' as table 'learningpipeline.serve.ChangeSince2010_metrowater15'\nSaved DataFrame for category 'CFGA23' as table 'learningpipeline.serve.ChangeSince2010_cfga23'\nSaved DataFrame for category 'GASenate' as table 'learningpipeline.serve.ChangeSince2010_gasenate'\nSaved DataFrame for category 'City' as table 'learningpipeline.serve.ChangeSince2010_city'\nSaved DataFrame for category 'HSSA' as table 'learningpipeline.serve.ChangeSince2010_hssa'\nSaved DataFrame for category 'ZCTA' as table 'learningpipeline.serve.ChangeSince2010_zcta'\nSaved DataFrame for category 'GAHouse' as table 'learningpipeline.serve.ChangeSince2010_gahouse'\nSaved DataFrame for category 'BeltLineStatisticalSub' as table 'learningpipeline.serve.ChangeSince2010_beltlinestatisticalsub'\nSaved DataFrame for category 'BeltLineStatistical' as table 'learningpipeline.serve.ChangeSince2010_beltlinestatistical'\nSaved DataFrame for category 'Congress' as table 'learningpipeline.serve.ChangeSince2010_congress'\nSaved DataFrame for category 'NSA' as table 'learningpipeline.serve.Demographic_nsa'\nSaved DataFrame for category 'Tract' as table 'learningpipeline.serve.Demographic_tract'\nSaved DataFrame for category 'NPU' as table 'learningpipeline.serve.Demographic_npu'\nSaved DataFrame for category 'County' as table 'learningpipeline.serve.Demographic_county'\nSaved DataFrame for category 'State' as table 'learningpipeline.serve.Demographic_state'\nSaved DataFrame for category 'RC' as table 'learningpipeline.serve.Demographic_rc'\nSaved DataFrame for category 'ARWDB7' as table 'learningpipeline.serve.Demographic_arwdb7'\nSaved DataFrame for category 'Nation' as table 'learningpipeline.serve.Demographic_nation'\nSaved DataFrame for category 'SuperDistrict' as table 'learningpipeline.serve.Demographic_superdistrict'\nSaved DataFrame for category 'AtlCityCouncil' as table 'learningpipeline.serve.Demographic_atlcitycouncil'\nSaved DataFrame for category 'UWGA13' as table 'learningpipeline.serve.Demographic_uwga13'\nSaved DataFrame for category 'ARC21' as table 'learningpipeline.serve.Demographic_arc21'\nSaved DataFrame for category 'AAA' as table 'learningpipeline.serve.Demographic_aaa'\nSaved DataFrame for category 'MetroWater15' as table 'learningpipeline.serve.Demographic_metrowater15'\nSaved DataFrame for category 'CFGA23' as table 'learningpipeline.serve.Demographic_cfga23'\nSaved DataFrame for category 'GASenate' as table 'learningpipeline.serve.Demographic_gasenate'\nSaved DataFrame for category 'City' as table 'learningpipeline.serve.Demographic_city'\nSaved DataFrame for category 'HSSA' as table 'learningpipeline.serve.Demographic_hssa'\nSaved DataFrame for category 'ZCTA' as table 'learningpipeline.serve.Demographic_zcta'\nSaved DataFrame for category 'GAHouse' as table 'learningpipeline.serve.Demographic_gahouse'\nSaved DataFrame for category 'BeltLineStatisticalSub' as table 'learningpipeline.serve.Demographic_beltlinestatisticalsub'\nSaved DataFrame for category 'BeltLineStatistical' as table 'learningpipeline.serve.Demographic_beltlinestatistical'\nSaved DataFrame for category 'Congress' as table 'learningpipeline.serve.Demographic_congress'\nSaved DataFrame for category 'NSA' as table 'learningpipeline.serve.Demographic_Population_nsa'\nSaved DataFrame for category 'Tract' as table 'learningpipeline.serve.Demographic_Population_tract'\nSaved DataFrame for category 'NPU' as table 'learningpipeline.serve.Demographic_Population_npu'\nSaved DataFrame for category 'County' as table 'learningpipeline.serve.Demographic_Population_county'\nSaved DataFrame for category 'State' as table 'learningpipeline.serve.Demographic_Population_state'\nSaved DataFrame for category 'RC' as table 'learningpipeline.serve.Demographic_Population_rc'\nSaved DataFrame for category 'ARWDB7' as table 'learningpipeline.serve.Demographic_Population_arwdb7'\nSaved DataFrame for category 'Nation' as table 'learningpipeline.serve.Demographic_Population_nation'\nSaved DataFrame for category 'SuperDistrict' as table 'learningpipeline.serve.Demographic_Population_superdistrict'\nSaved DataFrame for category 'AtlCityCouncil' as table 'learningpipeline.serve.Demographic_Population_atlcitycouncil'\nSaved DataFrame for category 'UWGA13' as table 'learningpipeline.serve.Demographic_Population_uwga13'\nSaved DataFrame for category 'ARC21' as table 'learningpipeline.serve.Demographic_Population_arc21'\nSaved DataFrame for category 'AAA' as table 'learningpipeline.serve.Demographic_Population_aaa'\nSaved DataFrame for category 'MetroWater15' as table 'learningpipeline.serve.Demographic_Population_metrowater15'\nSaved DataFrame for category 'CFGA23' as table 'learningpipeline.serve.Demographic_Population_cfga23'\nSaved DataFrame for category 'GASenate' as table 'learningpipeline.serve.Demographic_Population_gasenate'\nSaved DataFrame for category 'City' as table 'learningpipeline.serve.Demographic_Population_city'\nSaved DataFrame for category 'HSSA' as table 'learningpipeline.serve.Demographic_Population_hssa'\nSaved DataFrame for category 'ZCTA' as table 'learningpipeline.serve.Demographic_Population_zcta'\nSaved DataFrame for category 'GAHouse' as table 'learningpipeline.serve.Demographic_Population_gahouse'\nSaved DataFrame for category 'BeltLineStatisticalSub' as table 'learningpipeline.serve.Demographic_Population_beltlinestatisticalsub'\nSaved DataFrame for category 'BeltLineStatistical' as table 'learningpipeline.serve.Demographic_Population_beltlinestatistical'\nSaved DataFrame for category 'Congress' as table 'learningpipeline.serve.Demographic_Population_congress'\nSaved DataFrame for category 'NSA' as table 'learningpipeline.serve.Demographic_RaceEth_nsa'\nSaved DataFrame for category 'Tract' as table 'learningpipeline.serve.Demographic_RaceEth_tract'\nSaved DataFrame for category 'NPU' as table 'learningpipeline.serve.Demographic_RaceEth_npu'\nSaved DataFrame for category 'County' as table 'learningpipeline.serve.Demographic_RaceEth_county'\nSaved DataFrame for category 'State' as table 'learningpipeline.serve.Demographic_RaceEth_state'\nSaved DataFrame for category 'RC' as table 'learningpipeline.serve.Demographic_RaceEth_rc'\nSaved DataFrame for category 'ARWDB7' as table 'learningpipeline.serve.Demographic_RaceEth_arwdb7'\nSaved DataFrame for category 'Nation' as table 'learningpipeline.serve.Demographic_RaceEth_nation'\nSaved DataFrame for category 'SuperDistrict' as table 'learningpipeline.serve.Demographic_RaceEth_superdistrict'\nSaved DataFrame for category 'AtlCityCouncil' as table 'learningpipeline.serve.Demographic_RaceEth_atlcitycouncil'\nSaved DataFrame for category 'UWGA13' as table 'learningpipeline.serve.Demographic_RaceEth_uwga13'\nSaved DataFrame for category 'ARC21' as table 'learningpipeline.serve.Demographic_RaceEth_arc21'\nSaved DataFrame for category 'AAA' as table 'learningpipeline.serve.Demographic_RaceEth_aaa'\nSaved DataFrame for category 'MetroWater15' as table 'learningpipeline.serve.Demographic_RaceEth_metrowater15'\nSaved DataFrame for category 'CFGA23' as table 'learningpipeline.serve.Demographic_RaceEth_cfga23'\nSaved DataFrame for category 'GASenate' as table 'learningpipeline.serve.Demographic_RaceEth_gasenate'\nSaved DataFrame for category 'City' as table 'learningpipeline.serve.Demographic_RaceEth_city'\nSaved DataFrame for category 'HSSA' as table 'learningpipeline.serve.Demographic_RaceEth_hssa'\nSaved DataFrame for category 'ZCTA' as table 'learningpipeline.serve.Demographic_RaceEth_zcta'\nSaved DataFrame for category 'GAHouse' as table 'learningpipeline.serve.Demographic_RaceEth_gahouse'\nSaved DataFrame for category 'BeltLineStatisticalSub' as table 'learningpipeline.serve.Demographic_RaceEth_beltlinestatisticalsub'\nSaved DataFrame for category 'BeltLineStatistical' as table 'learningpipeline.serve.Demographic_RaceEth_beltlinestatistical'\nSaved DataFrame for category 'Congress' as table 'learningpipeline.serve.Demographic_RaceEth_congress'\nSaved DataFrame for category 'NSA' as table 'learningpipeline.serve.Demographic_SexAge_nsa'\nSaved DataFrame for category 'Tract' as table 'learningpipeline.serve.Demographic_SexAge_tract'\nSaved DataFrame for category 'NPU' as table 'learningpipeline.serve.Demographic_SexAge_npu'\nSaved DataFrame for category 'County' as table 'learningpipeline.serve.Demographic_SexAge_county'\nSaved DataFrame for category 'State' as table 'learningpipeline.serve.Demographic_SexAge_state'\nSaved DataFrame for category 'RC' as table 'learningpipeline.serve.Demographic_SexAge_rc'\nSaved DataFrame for category 'ARWDB7' as table 'learningpipeline.serve.Demographic_SexAge_arwdb7'\nSaved DataFrame for category 'Nation' as table 'learningpipeline.serve.Demographic_SexAge_nation'\nSaved DataFrame for category 'SuperDistrict' as table 'learningpipeline.serve.Demographic_SexAge_superdistrict'\nSaved DataFrame for category 'AtlCityCouncil' as table 'learningpipeline.serve.Demographic_SexAge_atlcitycouncil'\nSaved DataFrame for category 'UWGA13' as table 'learningpipeline.serve.Demographic_SexAge_uwga13'\nSaved DataFrame for category 'ARC21' as table 'learningpipeline.serve.Demographic_SexAge_arc21'\nSaved DataFrame for category 'AAA' as table 'learningpipeline.serve.Demographic_SexAge_aaa'\nSaved DataFrame for category 'MetroWater15' as table 'learningpipeline.serve.Demographic_SexAge_metrowater15'\nSaved DataFrame for category 'CFGA23' as table 'learningpipeline.serve.Demographic_SexAge_cfga23'\nSaved DataFrame for category 'GASenate' as table 'learningpipeline.serve.Demographic_SexAge_gasenate'\nSaved DataFrame for category 'City' as table 'learningpipeline.serve.Demographic_SexAge_city'\nSaved DataFrame for category 'HSSA' as table 'learningpipeline.serve.Demographic_SexAge_hssa'\nSaved DataFrame for category 'ZCTA' as table 'learningpipeline.serve.Demographic_SexAge_zcta'\nSaved DataFrame for category 'GAHouse' as table 'learningpipeline.serve.Demographic_SexAge_gahouse'\nSaved DataFrame for category 'BeltLineStatisticalSub' as table 'learningpipeline.serve.Demographic_SexAge_beltlinestatisticalsub'\nSaved DataFrame for category 'BeltLineStatistical' as table 'learningpipeline.serve.Demographic_SexAge_beltlinestatistical'\nSaved DataFrame for category 'Congress' as table 'learningpipeline.serve.Demographic_SexAge_congress'\nSaved DataFrame for category 'NSA' as table 'learningpipeline.serve.Demographic_VotingAge_nsa'\nSaved DataFrame for category 'Tract' as table 'learningpipeline.serve.Demographic_VotingAge_tract'\nSaved DataFrame for category 'NPU' as table 'learningpipeline.serve.Demographic_VotingAge_npu'\nSaved DataFrame for category 'County' as table 'learningpipeline.serve.Demographic_VotingAge_county'\nSaved DataFrame for category 'State' as table 'learningpipeline.serve.Demographic_VotingAge_state'\nSaved DataFrame for category 'RC' as table 'learningpipeline.serve.Demographic_VotingAge_rc'\nSaved DataFrame for category 'ARWDB7' as table 'learningpipeline.serve.Demographic_VotingAge_arwdb7'\nSaved DataFrame for category 'Nation' as table 'learningpipeline.serve.Demographic_VotingAge_nation'\nSaved DataFrame for category 'SuperDistrict' as table 'learningpipeline.serve.Demographic_VotingAge_superdistrict'\nSaved DataFrame for category 'AtlCityCouncil' as table 'learningpipeline.serve.Demographic_VotingAge_atlcitycouncil'\nSaved DataFrame for category 'UWGA13' as table 'learningpipeline.serve.Demographic_VotingAge_uwga13'\nSaved DataFrame for category 'ARC21' as table 'learningpipeline.serve.Demographic_VotingAge_arc21'\nSaved DataFrame for category 'AAA' as table 'learningpipeline.serve.Demographic_VotingAge_aaa'\nSaved DataFrame for category 'MetroWater15' as table 'learningpipeline.serve.Demographic_VotingAge_metrowater15'\nSaved DataFrame for category 'CFGA23' as table 'learningpipeline.serve.Demographic_VotingAge_cfga23'\nSaved DataFrame for category 'GASenate' as table 'learningpipeline.serve.Demographic_VotingAge_gasenate'\nSaved DataFrame for category 'City' as table 'learningpipeline.serve.Demographic_VotingAge_city'\nSaved DataFrame for category 'HSSA' as table 'learningpipeline.serve.Demographic_VotingAge_hssa'\nSaved DataFrame for category 'ZCTA' as table 'learningpipeline.serve.Demographic_VotingAge_zcta'\nSaved DataFrame for category 'GAHouse' as table 'learningpipeline.serve.Demographic_VotingAge_gahouse'\nSaved DataFrame for category 'BeltLineStatisticalSub' as table 'learningpipeline.serve.Demographic_VotingAge_beltlinestatisticalsub'\nSaved DataFrame for category 'BeltLineStatistical' as table 'learningpipeline.serve.Demographic_VotingAge_beltlinestatistical'\nSaved DataFrame for category 'Congress' as table 'learningpipeline.serve.Demographic_VotingAge_congress'\nSaved DataFrame for category 'NSA' as table 'learningpipeline.serve.Econ_Commuting_nsa'\nSaved DataFrame for category 'Tract' as table 'learningpipeline.serve.Econ_Commuting_tract'\nSaved DataFrame for category 'NPU' as table 'learningpipeline.serve.Econ_Commuting_npu'\nSaved DataFrame for category 'County' as table 'learningpipeline.serve.Econ_Commuting_county'\nSaved DataFrame for category 'State' as table 'learningpipeline.serve.Econ_Commuting_state'\nSaved DataFrame for category 'RC' as table 'learningpipeline.serve.Econ_Commuting_rc'\nSaved DataFrame for category 'ARWDB7' as table 'learningpipeline.serve.Econ_Commuting_arwdb7'\nSaved DataFrame for category 'Nation' as table 'learningpipeline.serve.Econ_Commuting_nation'\nSaved DataFrame for category 'SuperDistrict' as table 'learningpipeline.serve.Econ_Commuting_superdistrict'\nSaved DataFrame for category 'AtlCityCouncil' as table 'learningpipeline.serve.Econ_Commuting_atlcitycouncil'\nSaved DataFrame for category 'UWGA13' as table 'learningpipeline.serve.Econ_Commuting_uwga13'\nSaved DataFrame for category 'ARC21' as table 'learningpipeline.serve.Econ_Commuting_arc21'\nSaved DataFrame for category 'AAA' as table 'learningpipeline.serve.Econ_Commuting_aaa'\nSaved DataFrame for category 'MetroWater15' as table 'learningpipeline.serve.Econ_Commuting_metrowater15'\nSaved DataFrame for category 'CFGA23' as table 'learningpipeline.serve.Econ_Commuting_cfga23'\nSaved DataFrame for category 'GASenate' as table 'learningpipeline.serve.Econ_Commuting_gasenate'\nSaved DataFrame for category 'City' as table 'learningpipeline.serve.Econ_Commuting_city'\nSaved DataFrame for category 'HSSA' as table 'learningpipeline.serve.Econ_Commuting_hssa'\nSaved DataFrame for category 'ZCTA' as table 'learningpipeline.serve.Econ_Commuting_zcta'\nSaved DataFrame for category 'GAHouse' as table 'learningpipeline.serve.Econ_Commuting_gahouse'\nSaved DataFrame for category 'BeltLineStatisticalSub' as table 'learningpipeline.serve.Econ_Commuting_beltlinestatisticalsub'\nSaved DataFrame for category 'BeltLineStatistical' as table 'learningpipeline.serve.Econ_Commuting_beltlinestatistical'\nSaved DataFrame for category 'Congress' as table 'learningpipeline.serve.Econ_Commuting_congress'\nSaved DataFrame for category 'NSA' as table 'learningpipeline.serve.Econ_HealthIns_nsa'\nSaved DataFrame for category 'Tract' as table 'learningpipeline.serve.Econ_HealthIns_tract'\nSaved DataFrame for category 'NPU' as table 'learningpipeline.serve.Econ_HealthIns_npu'\nSaved DataFrame for category 'County' as table 'learningpipeline.serve.Econ_HealthIns_county'\nSaved DataFrame for category 'State' as table 'learningpipeline.serve.Econ_HealthIns_state'\nSaved DataFrame for category 'RC' as table 'learningpipeline.serve.Econ_HealthIns_rc'\nSaved DataFrame for category 'ARWDB7' as table 'learningpipeline.serve.Econ_HealthIns_arwdb7'\nSaved DataFrame for category 'Nation' as table 'learningpipeline.serve.Econ_HealthIns_nation'\nSaved DataFrame for category 'SuperDistrict' as table 'learningpipeline.serve.Econ_HealthIns_superdistrict'\nSaved DataFrame for category 'AtlCityCouncil' as table 'learningpipeline.serve.Econ_HealthIns_atlcitycouncil'\nSaved DataFrame for category 'UWGA13' as table 'learningpipeline.serve.Econ_HealthIns_uwga13'\nSaved DataFrame for category 'ARC21' as table 'learningpipeline.serve.Econ_HealthIns_arc21'\nSaved DataFrame for category 'AAA' as table 'learningpipeline.serve.Econ_HealthIns_aaa'\nSaved DataFrame for category 'MetroWater15' as table 'learningpipeline.serve.Econ_HealthIns_metrowater15'\nSaved DataFrame for category 'CFGA23' as table 'learningpipeline.serve.Econ_HealthIns_cfga23'\nSaved DataFrame for category 'GASenate' as table 'learningpipeline.serve.Econ_HealthIns_gasenate'\nSaved DataFrame for category 'City' as table 'learningpipeline.serve.Econ_HealthIns_city'\nSaved DataFrame for category 'HSSA' as table 'learningpipeline.serve.Econ_HealthIns_hssa'\nSaved DataFrame for category 'ZCTA' as table 'learningpipeline.serve.Econ_HealthIns_zcta'\nSaved DataFrame for category 'GAHouse' as table 'learningpipeline.serve.Econ_HealthIns_gahouse'\nSaved DataFrame for category 'BeltLineStatisticalSub' as table 'learningpipeline.serve.Econ_HealthIns_beltlinestatisticalsub'\nSaved DataFrame for category 'BeltLineStatistical' as table 'learningpipeline.serve.Econ_HealthIns_beltlinestatistical'\nSaved DataFrame for category 'Congress' as table 'learningpipeline.serve.Econ_HealthIns_congress'\nSaved DataFrame for category 'NSA' as table 'learningpipeline.serve.Econ_Income_nsa'\nSaved DataFrame for category 'Tract' as table 'learningpipeline.serve.Econ_Income_tract'\nSaved DataFrame for category 'NPU' as table 'learningpipeline.serve.Econ_Income_npu'\nSaved DataFrame for category 'County' as table 'learningpipeline.serve.Econ_Income_county'\nSaved DataFrame for category 'State' as table 'learningpipeline.serve.Econ_Income_state'\nSaved DataFrame for category 'RC' as table 'learningpipeline.serve.Econ_Income_rc'\nSaved DataFrame for category 'ARWDB7' as table 'learningpipeline.serve.Econ_Income_arwdb7'\nSaved DataFrame for category 'Nation' as table 'learningpipeline.serve.Econ_Income_nation'\nSaved DataFrame for category 'SuperDistrict' as table 'learningpipeline.serve.Econ_Income_superdistrict'\nSaved DataFrame for category 'AtlCityCouncil' as table 'learningpipeline.serve.Econ_Income_atlcitycouncil'\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "com.databricks.backend.common.rpc.CommandCancelledException\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$5(SequenceExecutionState.scala:136)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:136)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)\n",
       "\tat scala.collection.immutable.Range.foreach(Range.scala:158)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:727)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:445)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:445)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.cancelExecution(ChauffeurState.scala:1268)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:985)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:68)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:68)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:68)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:68)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:946)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:782)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:808)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:807)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:862)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:655)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:147)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1020)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:941)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:545)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:514)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:405)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:58)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$1(ActivityContextFactory.scala:405)\n",
       "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:44)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:380)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:159)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:514)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:404)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n",
       "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n",
       "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
       "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
       "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n",
       "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
       "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$4(InstrumentedQueuedThreadPool.scala:104)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:47)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:104)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:66)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:63)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:47)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:86)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.lang.Thread.run(Thread.java:750)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Cancelled"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "com.databricks.backend.common.rpc.CommandCancelledException",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$5(SequenceExecutionState.scala:136)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:136)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)",
        "\tat scala.collection.immutable.Range.foreach(Range.scala:158)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:727)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:445)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:445)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.cancelExecution(ChauffeurState.scala:1268)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:985)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:68)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:68)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:68)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:68)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:946)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:782)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:808)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:807)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:862)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:655)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)",
        "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:147)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1020)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:941)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:545)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:514)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:405)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:58)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$1(ActivityContextFactory.scala:405)",
        "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:44)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:380)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:159)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:514)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:404)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)",
        "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)",
        "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)",
        "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)",
        "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)",
        "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)",
        "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)",
        "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)",
        "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)",
        "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)",
        "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$4(InstrumentedQueuedThreadPool.scala:104)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:47)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:104)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:66)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:63)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:47)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:86)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)",
        "\tat java.lang.Thread.run(Thread.java:750)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example DataFrame\n",
    "\n",
    "fs_vals = dbutils.fs.ls(\"/Volumes/learningpipeline/bronze/raw_data_values\")\n",
    "\n",
    "for data_table in fs_vals:\n",
    "    df = spark.table(f\"learningpipeline.silver.{data_table.name[0:-4]}\")\n",
    "\n",
    "    # Get unique values in the 'category' column\n",
    "    unique_sumlev = [row['SUMLEV'] for row in df.select(\"SUMLEV\").distinct().collect()]\n",
    "\n",
    "    # Define the target schema name where tables will be saved\n",
    "    target_schema = \"learningpipeline.serve\"\n",
    "\n",
    "    # Loop through each unique category and save each filtered DataFrame as a table\n",
    "    for sumlev in unique_sumlev:\n",
    "        # Filter the DataFrame by the current category\n",
    "        filtered_df = df.filter(df[\"SUMLEV\"] == sumlev)\n",
    "        \n",
    "        # Define the table name\n",
    "        table_name = f\"{target_schema}.{data_table.name[0:-4]}_{sumlev.lower()}\"  # Example: table_a, table_b, etc.\n",
    "        \n",
    "        # Save the filtered DataFrame as a table\n",
    "        filtered_df.write.mode(\"overwrite\").option(\"overwriteSchema\",\"true\").saveAsTable(table_name)\n",
    "        \n",
    "        print(f\"Saved DataFrame for category '{sumlev}' as table '{table_name}'\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 765371907976552,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "split_geojoin_df_by_geo",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
